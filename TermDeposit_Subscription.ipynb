{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you'd like to install packages that aren't installed by default, uncomment the last two lines of this cell and replace <package list> with a list of your packages.\n",
    "# This will ensure your notebook has all the dependencies and works everywhere\n",
    "\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install <package list>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", 101)\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Column | Description\n",
    ":---|:---\n",
    "`client_id` | Unique ID of the client called [unique key]\n",
    "`age_bracket` | Age bracket of the contacted client (in years)\n",
    "`job` | job type of the contacted client\n",
    "`marital` | marital status of the contacted client\n",
    "`education` | highest level of education done by the client\n",
    "`has_housing_loan` | Whether the client has a house loan (binary: yes,no)\n",
    "`has_personal_loan` | Whether the client has a personal loan (binary: yes,no)\n",
    "`prev_call_duration` | last contact duration (value = 0 if the client has not been contacted ever)\n",
    "`days_since_last_call` | number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "`num_contacts_prev` | number of contacts performed before this campaign and for this client (numeric)\n",
    "`poutcome` | outcome of the previous marketing campaign (categorical: \"failure\",\"nonexistent\",\"success\")\n",
    "`contact_date` | date at which contact was made with the client (YYYY-MM-DD)\n",
    "`cpi` | standing consumer price index before the call (monthly indicator)\n",
    "`subs_deposit` | has the client subscribed to a term deposit? (binary: 1,0) [dependent variable]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Train data\n",
    "data_train = pd.read_csv(\"train.csv\", parse_dates = ['contact_date'])\n",
    "data_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Test data\n",
    "data_test=pd.read_csv(\"test.csv\",parse_dates = ['contact_date'])\n",
    "print(data_test.shape)\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore columns\n",
    "data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Description\n",
    "data_train.describe(percentiles = [0.05,0.5,0.95,0.975,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if any columns has null values\n",
    "data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if any columns has NA values\n",
    "data_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization, Modeling, Machine Learning\n",
    "\n",
    " Can you help Lending Bank to predict whether a client would subscribe to the term deposit and explain how different features affect that? Please explain your findings effectively to technical and non-technical audiences using comments and visualizations, if appropriate.\n",
    "- **Build an optimized model that effectively solves the business problem.**\n",
    "- **The model would be evaluated on the basis of F1 score.**\n",
    "- **Read the test.csv file and prepare features for testing.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying data in each column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.subs_deposit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.subs_deposit.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 60% of clients in the dataset haven't subscribed a term deposit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.age_bracket.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.age_bracket.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.job.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.job.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.marital.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.marital.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.education.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.education.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.has_housing_loan.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.has_housing_loan.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.has_personal_loan.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.has_personal_loan.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.prev_call_duration.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.days_since_last_call.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[data_train.days_since_last_call==999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[data_test.days_since_last_call==999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.num_contacts_prev.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.poutcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.cpi.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data_train.subs_deposit)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Majority of clients havent subscribed to a term deposit as per the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=data_train, x='age_bracket', hue= 'subs_deposit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clients in the age bracket of 60+ and 18-24 are more like to have term deposits than others. Dataset has more population of clients in the age group of 41-60 and 25-60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_dim = (10, 9)\n",
    "fig, ax = plt.subplots(figsize=ax_dim)\n",
    "sns.countplot(ax = ax, data=data_train, x='job', hue= 'subs_deposit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clients whose job is not specified is more likey to have term deposits compared to others\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.countplot(data=data_train, x='marital', hue= 'subs_deposit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marital Status doesnt seem to have any impact having a term deposit or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_dim = (10, 9)\n",
    "fig, ax = plt.subplots(figsize=ax_dim)\n",
    "sns.countplot(ax= ax, data=data_train, x='education', hue= 'subs_deposit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority of the clients have education level of secondary school or higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=data_train, x='has_housing_loan', hue= 'subs_deposit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=data_train, x='has_personal_loan', hue= 'subs_deposit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=data_train, x='poutcome', hue= 'subs_deposit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot numerical features\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "data_train.hist(bins=20, figsize=(14,10), color='#E14906')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* client_id has no relevance to determine the target variable here.\n",
    "* cpi is between 90 and 100 for most of the records except a few outliers with more than 900\n",
    "* prev_call_duration is mostly witiin 1000 seconds except some outliers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_feature_data(df):\n",
    "    '''\n",
    "    Method to process features in a dataframe\n",
    "    Create an additional feature based on the column days_since_last_call \n",
    "    Create additional features based contact data\n",
    "    Drop unnecessary columns\n",
    "    '''\n",
    "    #Create an additional feature based on the column days_since_last_call\n",
    "    \n",
    "    df['prev_contact_flag'] = np.where(df.days_since_last_call == 999, 0,1) \n",
    "    df['days_since_last_call'].replace({999: 0}, inplace = True) \n",
    "    \n",
    "    #Create additional features based contact data\n",
    "    df['contact_year'] = pd.DatetimeIndex(df['contact_date']).year\n",
    "    df['contact_month'] = pd.DatetimeIndex(df['contact_date']).month\n",
    "    df['contact_day'] = pd.DatetimeIndex(df['contact_date']).day\n",
    "    \n",
    "    #Drop unnecessary columns\n",
    "    drop_features = ['client_id','contact_year', 'contact_date']\n",
    "    df.drop(drop_features, axis=1,inplace = True)\n",
    "       \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data_train.copy(deep = True)\n",
    "train_df = process_feature_data(train_df)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categorical columns TO Dummy Variables and drop unnecessary columns\n",
    "train_df = pd.get_dummies(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "train_df.corr()['subs_deposit'].sort_values()[:-1].plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get features and target variables\n",
    "X = train_df.drop(['subs_deposit'], axis=1)\n",
    "y = train_df['subs_deposit']\n",
    "features = X.columns\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix, f1_score, accuracy_score\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', C=1, solver='lbfgs')\n",
    "dtree = DecisionTreeClassifier(criterion= 'gini', min_samples_split=8,\n",
    "                                  min_samples_leaf = 4, max_features = 'auto')\n",
    "rfc = RandomForestClassifier(n_estimators=400)\n",
    "gbc = GradientBoostingClassifier(n_estimators=400, max_depth=5)\n",
    "\n",
    "models.extend([lr,dtree, rfc,gbc])\n",
    "\n",
    "for model in models:\n",
    "    print(model)\n",
    "    model.fit(x_train, y_train)\n",
    "    ypred = model.predict(x_test)\n",
    "    print(\"accuracy_score: %0.2f\" %(accuracy_score(y_test, ypred)))\n",
    "    print()\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(y_test, ypred))\n",
    "    print()\n",
    "    print(\"f1_score: %0.2f\" %(f1_score(y_test, ypred)))\n",
    "    print()\n",
    "    print('*******************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoostingClassifier model has given best f1_score and accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> #### Task:\n",
    "- **Visualize the top 20 features and their feature importance.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = gbc.feature_importances_    \n",
    "feature_importances = pd.DataFrame({'feature':features, 'importance':importances})\n",
    "feature_importances.sort_values(by='importance', ascending=False, inplace=True)\n",
    "#set index to 'feature'\n",
    "feature_importances.set_index('feature', inplace=True, drop=True)\n",
    "feature_importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances[0:10].plot.bar(figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot Predicted Vs Actual Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predicated_actual_distribution(model, x, y):\n",
    "    y_pred = model.predict(x)\n",
    "    figure, axes = plt.subplots(ncols=2)\n",
    "    figure.set_size_inches(10, 4)\n",
    "    sns.countplot(y, ax=axes[0])\n",
    "    axes[0].set_title('Actual Data Distribution')\n",
    "    sns.countplot(y_pred, ax=axes[1])\n",
    "    axes[1].set_title('Predicted Data Distribution')\n",
    "    \n",
    "    print('Y')\n",
    "    print(y[0:5])\n",
    "    print('Y_PRED')\n",
    "    print(y_pred[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_gbm = rfc.predict(x_test)\n",
    "\n",
    "plot_predicated_actual_distribution(gbc, x_test, y_predict_gbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Task:\n",
    "- **Submit the predictions on the test dataset using your optimized model** <br/>\n",
    "    For each record in the Test set (test.csv), you must predict the 'subs_deposit' variable (1/0). The 1/0 would depend on the **best F1 score**.\n",
    "    You should submit a CSV file with test entries plus a header row. Your submission will show an error if you have extra columns beyond 'client_id' and 'subs_deposit' or extra rows.\n",
    "The file (`submission.csv`) should have exactly 2 columns:\n",
    "    - **client_id**\n",
    "    - **subs_deposit** (contains 1/0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = data_test.copy(deep = True)\n",
    "#process features from test data set\n",
    "test_df = process_feature_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change categorical test features to numeric variables\n",
    "test_df = pd.get_dummies(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict test data using GradientBoostingClassifier\n",
    "yT = gbc.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub = data_test.copy(deep = True)\n",
    "data_sub['subs_deposit'] = yT\n",
    "data_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub.subs_deposit.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub.subs_deposit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub[['client_id','subs_deposit']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub[['client_id','subs_deposit']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submission\n",
    "data_sub[['client_id','subs_deposit']].to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
